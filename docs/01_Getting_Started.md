# ğŸ’» 01. ì„¤ì¹˜ ë° ì‹¤í–‰ ê°€ì´ë“œ (Getting Started)

ì´ ë¬¸ì„œëŠ” 'Project: Cortex'ì˜ ë¡œì»¬ ê°œë°œ í™˜ê²½ì„ ì„¤ì •í•˜ê³ , í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

## 1. í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ (Prerequisites)

- [Node.js](https://nodejs.org/) v20.x ì´ìƒ
- [Python](https://www.python.org/) 3.11.x ì´ìƒ
- [Docker Desktop](https://www.docker.com/products/docker-desktop/)

## 2. í”„ë¡œì íŠ¸ í´ë¡ 

```bash
git clone https://github.com/sleepyMS/Cortex.git
cd Cortex
```

## 3. í•„ìˆ˜ ì„œë¹„ìŠ¤ ì‹¤í–‰ (Docker)

> docker-compose.yml íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì´ íŒŒì¼ì€ ë°ì´í„°ë² ì´ìŠ¤(PostgreSQL/TimescaleDB)ì™€ ë©”ì‹œì§€ ë¸Œë¡œì»¤(Redis)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë”ì—ì„œ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
docker-compose up -d
```

- ìœ„ ëª…ë ¹ì€ ë¡œì»¬ PCì— ê°œë°œì— í•„ìš”í•œ ëª¨ë“  ì„œë¹„ìŠ¤(DB, Redis)ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ì‹œí‚µë‹ˆë‹¤.

## 4. ë°±ì—”ë“œ ì„¤ì • ë° ì‹¤í–‰

> ì´ 2ê°œì˜ í„°ë¯¸ë„ì´ í•„ìš”í•©ë‹ˆë‹¤. (1: FastAPI ì›¹ ì„œë²„, 2: Celery ì›Œì»¤)

### í„°ë¯¸ë„ 1: FastAPI ì›¹ ì„œë²„ ì‹¤í–‰

```bash
# 1. ë°±ì—”ë“œ í´ë”ë¡œ ì´ë™ ë° ê°€ìƒí™˜ê²½ ìƒì„±/í™œì„±í™”
cd backend
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # macOS/Linux

# 2. ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜
# (í”„ë¡œì íŠ¸ì— requirements.txtê°€ ìˆë‹¤ë©´ 'pip install -r requirements.txt' ì‚¬ìš©)
pip install fastapi "uvicorn[standard]" sqlalchemy psycopg2-binary passlib[bcrypt] polars "python-jose[cryptography]" celery redis

# 3. í™˜ê²½ë³€ìˆ˜ íŒŒì¼(.env) ìƒì„± ë° ì„¤ì •
# backend/.env íŒŒì¼ì„ ìƒì„±í•˜ê³  ì•„ë˜ ë‚´ìš©ì„ ì±„ì›ë‹ˆë‹¤.
DATABASE_URL="postgresql://cortex_user:cortex_password@localhost:5432/cortex_db"
REDIS_URL="redis://localhost:6379/0"
SECRET_KEY="<[https://random-string-generator.com/](https://random-string-generator.com/) ì—ì„œ ìƒì„±í•œ ê¸´ ë¬´ì‘ìœ„ ë¬¸ìì—´ë¡œ êµì²´>"
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=60

# 4. FastAPI ì›¹ ì„œë²„ ì‹¤í–‰
uvicorn main:app --reload
```

- **í™•ì¸:** ë¸Œë¼ìš°ì €ì—ì„œ `http://127.0.0.1:8000` ì ‘ì† ì‹œ "Hello World" ë˜ëŠ” API ë¬¸ì„œê°€ ë³´ì´ë©´ ì„±ê³µì…ë‹ˆë‹¤.

### í„°ë¯¸ë„ 2: Celery ì›Œì»¤ ì‹¤í–‰

```bash
# 1. ë°±ì—”ë“œ í´ë”ë¡œ ì´ë™ ë° ê°€ìƒí™˜ê²½ í™œì„±í™” (ì´ë¯¸ í–ˆë‹¤ë©´ ìƒëµ)
cd backend
.\venv\Scripts\activate # Windows
# source venv/bin/activate # macOS/Linux

# 2. Celery ì›Œì»¤ ì‹¤í–‰
# (main.pyê°€ ì•„ë‹Œ, celery ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ: worker.py)
celery -A app.worker worker -l info
# celery -A app.worker:celery_app worker -l info -P solo # ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ì€ ë–¨ì–´ì§€ì§€ë§Œ, Windows í™˜ê²½ê³¼ì˜ í˜¸í™˜ì„±ì´ ê°€ì¥ ë›°ì–´ë‚˜ ê°œë°œ ë° í…ŒìŠ¤íŠ¸ ëª©ì 
```

- **í™•ì¸:** í„°ë¯¸ë„ì— Celery ë¡œê³ ì™€ í•¨ê»˜ `[tasks]` ëª©ë¡ì´ ë³´ì´ê³  `ready` ìƒíƒœê°€ ë˜ë©´ ì„±ê³µì…ë‹ˆë‹¤. ì´ í„°ë¯¸ë„ì€ ê³„ì† ì‹¤í–‰ ìƒíƒœë¡œ ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.

## 5. í”„ë¡ íŠ¸ì—”ë“œ ì„¤ì • ë° ì‹¤í–‰

> ìƒˆë¡œìš´ í„°ë¯¸ë„ì´ í•„ìš”í•©ë‹ˆë‹¤.

```bash
# 1. í”„ë¡ íŠ¸ì—”ë“œ í´ë”ë¡œ ì´ë™
cd frontend

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
npm install

# 3. í™˜ê²½ë³€ìˆ˜ íŒŒì¼(.env.local) ìƒì„± ë° ì„¤ì •
# frontend/.env.local íŒŒì¼ì„ ìƒì„±í•˜ê³  ì•„ë˜ ë‚´ìš©ì„ ì±„ì›ë‹ˆë‹¤.
NEXT_PUBLIC_API_URL="[http://127.0.0.1:8000](http://127.0.0.1:8000)"

# 4. ê°œë°œ ì„œë²„ ì‹¤í–‰
npm run dev
```

- **í™•ì¸:** ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:3000` ì ‘ì† ì‹œ Next.js ì‹œì‘ í˜ì´ì§€ê°€ ë³´ì´ë©´ ì„±ê³µì…ë‹ˆë‹¤.

---

## 6. Alembic ì„¤ì • ë° ì‚¬ìš©ë²•

```bash
cd backend
pip install alembic
alembic init migrations # alembic.ini ì„¤ì • íŒŒì¼ì„ ìƒì„±
```

- ìƒì„±ëœ `alembic.ini` íŒŒì¼ì„ ì—´ì–´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. `sqlalchemy.url` ë¶€ë¶„ì„ `DATABASE_URL` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.

```bash
# alembic.ini (ì¼ë¶€ ë‚´ìš©)

# ...
[alembic]
script_location = migrations
sqlalchemy.url = %(DATABASE_URL)s # DATABASE_URL í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½

# ... (ë‹¤ë¥¸ ì„¤ì •ë“¤)
```

- **migrations/env.py íŒŒì¼ ì„¤ì •**

```python
from logging.config import fileConfig
import os
import sys
from dotenv import load_dotenv

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

load_dotenv(os.path.join(os.getcwd(), '..', '.env'))

# target_metadataë¥¼ ì„í¬íŠ¸í•  ëª¨ë¸ì˜ Baseë¡œ ì„¤ì •
# ì˜ˆì‹œ: from myapp.models import Base
# Project: Cortexì˜ ê²½ìš°, backend/app/models.pyì—ì„œ Baseë¥¼ ì„í¬íŠ¸
# sys.pathì— backend/app ë””ë ‰í† ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ models ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•¨
sys.path.append(os.path.join(os.getcwd(), 'app'))
from app.database import Base # app.databaseì—ì„œ Base ì„í¬íŠ¸ (BaseëŠ” modelsì—ì„œ ì •ì˜ë  ìˆ˜ë„ ìˆìŒ)
target_metadata = Base.metadata

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = os.getenv("DATABASE_URL")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    # config.get_sectionì—ì„œ sqlalchemy.urlì„ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³ ,
    # offline ëª¨ë“œì™€ ë™ì¼í•˜ê²Œ os.getenv("DATABASE_URL")ì„ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
    # ì´ëŠ” alembic.iniì˜ %(DATABASE_URL)s ë³€ìˆ˜ ëŒ€ì²´ê°€ ì‹¤íŒ¨í•  ë•Œì˜ ìš°íšŒì±…ì…ë‹ˆë‹¤.
    connectable = engine_from_config(
        {"sqlalchemy.url": os.getenv("DATABASE_URL")},
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

- **ì´ˆê¸° ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±**

```bash
alembic revision --autogenerate -m "Create initial tables"
alembic upgrade head
```

- ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©´ `migrations/versions/` ë””ë ‰í† ë¦¬ ì•ˆì— `<timestamp>_create_initial_tables.py`ì™€ ê°™ì€ ì´ë¦„ì˜ íŒŒì¼ì´ ìƒì„±ë  ê²ƒì…ë‹ˆë‹¤. ì´ íŒŒì¼ì„ ì—´ì–´ë³´ê³  `SQLAlchemy` ëª¨ë¸ì— ë”°ë¼ í…Œì´ë¸” ìƒì„± ì½”ë“œê°€ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í–¥í›„ ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ

- 1. ëª¨ë¸ ë³€ê²½: `backend/app/models.py`ì—ì„œ `SQLAlchemy` ëª¨ë¸ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

```bash
# ìƒˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±:
alembic revision --autogenerate -m "Add new_column to users table"
# ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ê²€í† : ìƒì„±ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼(migrations/versions/<timestamp>_*.py)ì„ ì—´ì–´ Alembicì´ ë³€ê²½ì‚¬í•­ì„ ì˜¬ë°”ë¥´ê²Œ ê°ì§€í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©:
alembic upgrade head
```

- ì´ ê³¼ì •ì„ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ê°œë°œê³¼ ë°°í¬ ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë°ì´í„° ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ìš”ì•½: ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤

ëª¨ë“  ì„¤ì •ì´ ëë‚˜ë©´, ë¡œì»¬ ê°œë°œì„ ìœ„í•´ ì•„ë˜ í”„ë¡œì„¸ìŠ¤ë“¤ì´ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤:

- **Docker:** PostgreSQL, Redis ì»¨í…Œì´ë„ˆ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
- **í„°ë¯¸ë„ 1:** FastAPI ì›¹ ì„œë²„ (`uvicorn`)
- **í„°ë¯¸ë„ 2:** Celery ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ (`celery`)
- **í„°ë¯¸ë„ 3:** Next.js ê°œë°œ ì„œë²„ (`npm run dev`)
